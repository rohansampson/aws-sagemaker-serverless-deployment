{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip -q install torch boto3 sagemaker transformers datasets[s3] --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset, test_dataset = load_dataset('imdb', split=['train', 'test'])\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column('label', 'labels')\n",
    "test_dataset = test_dataset.rename_column('label', 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()  \n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'hugging-face/demo'\n",
    "\n",
    "training_input_path = f's3://{bucket}/{prefix}/train'\n",
    "train_dataset.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "test_input_path = f's3://{bucket}/{prefix}/test'\n",
    "test_dataset.save_to_disk(test_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_input_path)\n",
    "print(test_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the Hugging Face model on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'epochs': 1,\n",
    "    'train_batch_size': 32,\n",
    "    'model_name':'distilbert-base-uncased'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_version='4.12.3'\n",
    "pytorch_version='1.9.1'\n",
    "py_version='py38'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.huggingface\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    role=role,\n",
    "    # Fine-tuning script\n",
    "    entry_point='train.py',\n",
    "    hyperparameters=hyperparameters,\n",
    "    # Infrastructure\n",
    "    transformers_version=transformers_version,\n",
    "    pytorch_version=pytorch_version,\n",
    "    py_version=py_version,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    # Managed Spot Training\n",
    "    use_spot_instances=True,\n",
    "    max_wait=3600,\n",
    "    max_run=3600,\n",
    "    # Disable profiling\n",
    "    disable_profiler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(\n",
    "    {'train': training_input_path, 'test': test_input_path}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_url = huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use boto3 to deploy with serverless inference\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm = boto3.client(service_name='sagemaker')\n",
    "sm_rt = boto3.client(service_name='sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "def name_with_timestamp(name):\n",
    "    return '{}-{}'.format(name, strftime('%Y-%m-%d-%H-%M-%S', gmtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model_name    = name_with_timestamp('huggingface-serverless')\n",
    "huggingface_epc_name      = name_with_timestamp('huggingface-serverless-epc')\n",
    "huggingface_endpoint_name = name_with_timestamp('huggingface-serverless-ep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='huggingface',\n",
    "    base_framework_version=f'pytorch{pytorch_version}',\n",
    "    region=region,\n",
    "    version=transformers_version,\n",
    "    py_version=py_version,\n",
    "    instance_type='ml.m5.large',   # No GPU support on serverless inference\n",
    "    image_scope='inference'\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_response = sm.create_model(\n",
    "    ModelName=huggingface_model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            'Image': image_uri,\n",
    "            'Mode': 'SingleModel',\n",
    "            'ModelDataUrl': model_data_url\n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "\n",
    "create_model_response[\"ModelArn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=huggingface_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'single-variant',\n",
    "            'ModelName': huggingface_model_name,\n",
    "            'ServerlessConfig': {\n",
    "                'MemorySizeInMB': 6144,\n",
    "                'MaxConcurrency': 8,\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "endpoint_config_response['EndpointConfigArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=huggingface_endpoint_name,\n",
    "    EndpointConfigName=huggingface_epc_name,\n",
    ")\n",
    "\n",
    "create_endpoint_response['EndpointArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=huggingface_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, threading, time, json\n",
    "\n",
    "sm_rt = boto3.client(service_name='sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to reuse an existing model and endpoint\n",
    "\n",
    "#model_data_url = 's3://sagemaker-us-west-2-754289655784/huggingface-pytorch-training-2021-12-07-14-01-17-832/output/model.tar.gz'\n",
    "#huggingface_endpoint_name ='huggingface-serverless-ep-2021-12-08-08-38-27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_16 = {'inputs': \"The Phantom Menace was a waste of my life. Die, Jar Jar, die!\"}\n",
    "\n",
    "test_data_250 = {'inputs': \"Naked but not afraid, a young man roams the forest, growling in all fours. \\\n",
    "He behaves like a beast. To him, this is not a theatrical exercise but the true manifestation of his instincts. \\\n",
    "In Nathalie Biancheri's offbeat drama “Wolf,” he is one in a group of teenagers convinced their fragile human \\\n",
    "bodies don’t correspond with their animal identities. Their condition, described as “species dysphoria,” \\\n",
    "ostracizes them from society.For Jacob (George MacKay), the wolf in question, being admitted into a facility \\\n",
    "where those afflicted receive corrective treatment is a last frontier between fulfilling his parents’ wish for \\\n",
    "normalcy or running wild without remorse.Jacob steps into a pack of fellow patients and meets among several \\\n",
    "others, Rufus (Fionn O'Shea), who thinks of himself as a lovable German Shepherd, and love interest Wildcat \\\n",
    "(Lily-Rose Depp), a long house-trained resident under the thumb of a key staff member. Some of them have a \\\n",
    "hard time adjusting, and get “prop privileges” to wear costumes that bring them closer to their desired form. \\\n",
    "Despite what it entails, the setup is never played for laughs, but the opposite. Their desperation has a deep \\\n",
    "sadness. But for as much writer/director Biancheri pumps copious ideas into this concept, the solemn tone and \\\n",
    "lack of thematic focus renders the overwrought outing underwhelming. A premise like this would have been more \\\n",
    "effective had it been executed with the acidity of someone like director Yorgos Lanthimos, in which the premise \\\n",
    "could unfold as satirical commentary rather than straightforward indignation. \"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = time.time()\n",
    "response = sm_rt.invoke_endpoint(\n",
    "            EndpointName=huggingface_endpoint_name,\n",
    "            Body=json.dumps(test_data_16),\n",
    "            ContentType='application/json'\n",
    ")\n",
    "tock = time.time()\n",
    "print(tock-tick)\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data_250\n",
    "num_predictions = 100\n",
    "num_threads = 8\n",
    "\n",
    "times=[]\n",
    "\n",
    "def predict():\n",
    "    thread_id = threading.get_ident()\n",
    "    print(f'Thread {thread_id} started.')\n",
    "\n",
    "    for i in range(num_predictions):\n",
    "        tick = time.time()\n",
    "        response = sm_rt.invoke_endpoint(\n",
    "            EndpointName=huggingface_endpoint_name,\n",
    "            Body=json.dumps(test_data),\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        tock = time.time()\n",
    "        #print(response[\"Body\"].read())\n",
    "        times.append((thread_id,tock-tick))\n",
    "\n",
    "for i in range(num_threads):\n",
    "    threading.Thread(target=predict, daemon=False).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [time for thread_id,time in times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import hist\n",
    "\n",
    "hist(t, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.percentile(t, q=[50,90,95,99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=huggingface_endpoint_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=huggingface_epc_name)\n",
    "sm.delete_model(ModelName=huggingface_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
